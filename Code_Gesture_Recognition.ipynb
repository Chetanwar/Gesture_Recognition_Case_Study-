{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition Case Study\n",
    "- **Team : Chetan D Wargantiwar & Karipe Uday Kumar**<br>\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started. Once you have completed the code you can download the notebook for making a submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "Imagine you are working as a data scientist at a home electronics company which manufactures state of the art smart televisions. You want to develop a cool feature in the smart-TV that can recognise five different gestures performed by the user which will help users control the TV without using a remote.<br>\n",
    "\n",
    "The gestures are continuously monitored by the webcam mounted on the TV. Each gesture corresponds to a specific command:<br>\n",
    "\n",
    "- Thumbs up: Increase the volume<br>\n",
    "- Thumbs down: Decrease the volume<br>\n",
    "- Left swipe: 'Jump' backwards 10 seconds<br>\n",
    "- Right swipe: 'Jump' forward 10 seconds<br>\n",
    "- Stop: Pause the movie<br>\n",
    "- Each video is a sequence of 30 frames (or images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "Need to accomplish the following in the project:<br>\n",
    "    1. **Generator**:  The generator should be able to take a batch of videos as input without any error. Steps like cropping, resizing and normalization should be performed successfully.<br><br>\n",
    "    2. **Model**: Develop a model that is able to train without any errors which will be judged on the total number of parameters (as the inference(prediction) time should be less) and the accuracy achieved. As suggested by Snehansu, start training on a small amount of data and then proceed further.<br><br>\n",
    "    3. **Write up**: This should contain the detailed procedure followed in choosing the final model. The write up should start with the reason for choosing the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-44b66b8ff9c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgetsizeof\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "import datetime\n",
    "import os\n",
    "from sys import getsizeof\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## importing Few More libraries needed for the model building.\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "## Checking the GPU configuration\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Gesture/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4114f0014433>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive/MyDrive/Gesture/train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive/MyDrive/Gesture/val.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Gesture/train.csv'"
     ]
    }
   ],
   "source": [
    "train_doc = np.random.permutation(open('/content/drive/MyDrive/Gesture/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('/content/drive/MyDrive/Gesture/val.csv').readlines())\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot the training/validation accuracies/losses.\n",
    "\n",
    "def plot(history):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
    "    axes[0].plot(history.history['loss'])   \n",
    "    axes[0].plot(history.history['val_loss'])\n",
    "    axes[0].legend(['loss','val_loss'])\n",
    "    axes[0].title.set_text(\"Train loss vs Validation loss\")\n",
    "\n",
    "    axes[1].plot(history.history['categorical_accuracy'])   \n",
    "    axes[1].plot(history.history['val_categorical_accuracy'])\n",
    "    axes[1].legend(['categorical_accuracy','val_categorical_accuracy'])\n",
    "    axes[1].title.set_text(\"Train accuracy vs Validation accuracy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator is updated to take follwoing parameters:<br>\n",
    "- **batch_size** - Size of the mini batches<br>\n",
    "- **frames_per_video** - Number of frames to be considered per video<br>\n",
    "- **height** - Resize dimension - height<br>\n",
    "- **width** - Resize dimension - width<br>\n",
    "- **apply_augmentation** - Boolean to indicate whether to apply augmentation or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters initialization\n",
    "image_width = 120   # X dimension of the image\n",
    "image_height = 120   # Y dimesnion of the image\n",
    "total_frames = 30  # lenght of the video frames\n",
    "channels = 3 # number of channels in images 3 for color(RGB) and 1 for Gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to generate a random affine transform on the iamge\n",
    "def get_random_affine():\n",
    "    dx, dy = np.random.randint(-1.7, 1.8, 2)\n",
    "    AF = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "    return AF\n",
    "\n",
    "# Helper function to initialize all the batch image data and labels\n",
    "def init_batch_data(batch_size):\n",
    "    batch_data = np.zeros((batch_size, total_frames, image_width, image_height, channels)) \n",
    "    batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "    return batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genarator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(source_path, folder_list, batch_size, augument_false=False):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            # you yield the batch_data and the batch_labels, remember what does yield do\n",
    "            yield load_batch_images(source_path, folder_list, batch, batch_size, t,augument_false)\n",
    "            \n",
    "\n",
    "        \n",
    "        # Code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "            yield load_batch_images(source_path, folder_list, batch, batch_size, t,augument_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch_images(source_path, folder_list, batch_num, batch_size, t,augument_false):\n",
    "    \n",
    "    batch_data,batch_labels = init_batch_data(batch_size)\n",
    "    \n",
    "    # We will also build an augumented batch data with affine transformation\n",
    "    batch_data_aug,batch_labels_aug = init_batch_data(batch_size)\n",
    "    \n",
    "    \n",
    "    #create a list of image numbers you want to use for a particular video using full frames\n",
    "    img_idx = [x for x in range(0, total_frames)] \n",
    "\n",
    "    for folder in range(batch_size): # iterate over the batch_size\n",
    "        # read all the images in the folder\n",
    "        imgs = sorted(os.listdir(source_path+'/'+ t[folder + (batch_num*batch_size)].split(';')[0])) \n",
    "        # Generate a random affine to be used in image transformation for buidling agumented data set\n",
    "        AF = get_random_affine()\n",
    "        \n",
    "        #  Iterate over the frames/images of a folder to read them in\n",
    "        for idx, item in enumerate(img_idx): \n",
    "            image = imread(source_path+'/'+ t[folder + (batch_num*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "            #crop the images and resize them. Note that the images are of 2 different shape \n",
    "            #and the conv3D will throw error if the inputs in a batch have different shapes \n",
    "            if image.shape[0] != image.shape[1]:\n",
    "                image=image[0:120,20:140]\n",
    "             \n",
    "            resized = cv2.resize(image, (image_height,image_width), interpolation = cv2.INTER_AREA) \n",
    "          \n",
    "            #Normalize data\n",
    "\n",
    "            batch_data[folder,idx,:,:,0] = cv2.normalize(resized[:,:,0],  None, 0.00, 1.00, cv2.NORM_MINMAX)\n",
    "            batch_data[folder,idx,:,:,1] = cv2.normalize(resized[:,:,1],  None, 0.00, 1.00, cv2.NORM_MINMAX)\n",
    "            batch_data[folder,idx,:,:,2] = cv2.normalize(resized[:,:,2],  None, 0.00, 1.00, cv2.NORM_MINMAX)\n",
    "            \n",
    "            #Data with affine transformation\n",
    "            affined = (cv2.warpAffine(resized, AF, (resized.shape[0], resized.shape[1])))\n",
    "\n",
    "            batch_data[folder,idx,:,:,0] = cv2.normalize(affined[:,:,0],  None, 0.00, 1.00, cv2.NORM_MINMAX)\n",
    "            batch_data[folder,idx,:,:,1] = cv2.normalize(affined[:,:,1],  None, 0.00, 1.00, cv2.NORM_MINMAX)\n",
    "            batch_data[folder,idx,:,:,2] = cv2.normalize(affined[:,:,2],  None, 0.00, 1.00, cv2.NORM_MINMAX)\n",
    "            \n",
    "            \n",
    "\n",
    "        batch_labels[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "        batch_labels_aug[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "        \n",
    "                      \n",
    "    \n",
    "    batch_data_final = np.append(batch_data, batch_data_aug, axis = 0)\n",
    "\n",
    "    batch_labels_final = np.append(batch_labels, batch_labels_aug, axis = 0) \n",
    "\n",
    "    \n",
    "    if augument_false:\n",
    "        batch_data_final=batch_data\n",
    "        batch_labels_final= batch_labels\n",
    "                \n",
    "    return batch_data_final,batch_labels_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = '/content/drive/MyDrive/Gesture/train'\n",
    "val_path = '/content/drive/MyDrive/Gesture/val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 10# choose the number of epochs\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genarator Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check complete batch shape\n",
    "sample_generator = generator(train_path, train_doc, batch_size, augument_false=True)\n",
    "sample_batch_data, sample_batch_labels = next(sample_generator)\n",
    "print(sample_batch_data.shape)\n",
    "\n",
    "# validation batch sample\n",
    "sample_val_generator = generator(val_path, val_doc, batch_size, augument_false=True)\n",
    "sample_val_batch_data, sample_val_batch_labels = next(sample_val_generator)\n",
    "print(sample_val_batch_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot generated sample images\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes[0].imshow(sample_batch_data[2,29,:,:,:])   \n",
    "axes[1].imshow(sample_batch_data[6,29,:,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot generated sample images\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes[0].imshow(sample_val_batch_data[2,29,:,:,:])   \n",
    "axes[1].imshow(sample_val_batch_data[6,29,:,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout, Flatten, BatchNormalization, Activation, Conv3D, MaxPooling3D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "def define_model():\n",
    "    filtersize = [8,16,32,64]\n",
    "    dense_neurons = [256, 128, 5]\n",
    "    \n",
    "    # Input\n",
    "    input_shape=(total_frames,image_width,image_height,channels)\n",
    "    # Define model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv3D(filtersize[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "    model.add(Conv3D(filtersize[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "    model.add(Conv3D(filtersize[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "    #Flatten Layers\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(dense_neurons[1], activation='relu'))\n",
    "\n",
    "    #softmax layer\n",
    "    model.add(Dense(dense_neurons[2], activation='softmax'))\n",
    "\n",
    "    optimiser = 'adam' #write your optimizer\n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model=define_model()\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit` method to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution of the sample model\n",
    "#batch_size = 512\n",
    "#num_epochs = 10\n",
    "#train_generator = generator(train_path, train_doc, batch_size, augument_false=True)\n",
    "#val_generator = generator(val_path, val_doc, batch_size, augument_false=True)\n",
    "\n",
    "#print(\"Total Params:\", base_model.count_params())\n",
    "#history_model_base =base_model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "#                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "#                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With batch_size=512 Error Seen<br>\n",
    "- ResourceExhaustedError:  OOM when allocating tensor with shape[512,8,30,14400] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    " Executing with lower batch sizes and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution of the sample model\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, augument_false=True)\n",
    "val_generator = generator(val_path, val_doc, batch_size, augument_false=True)\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"Total Params:\", base_model.count_params())\n",
    "history_model1 =base_model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the score\n",
    "plot(history_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "There is a difference in training and validation, Looks like there is overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 15\n",
    "\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size, augument_false=True)\n",
    "\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"Total Params:\", base_model.count_params())\n",
    "history_model2 =base_model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the score\n",
    "plot(history_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "Data augmentation does not help here, We will not use the augmented data in any of the model in this case study.\n",
    "We will now tune the model by reducing filter sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Base Model\n",
    "Lets Reduce the filter Size to (2,2,2), to see if that improve the performace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    filtersize = [8,16,32,64]\n",
    "    dense_neurons = [256, 128, 5]\n",
    "    \n",
    "    # Input\n",
    "    input_shape=(total_frames,image_width,image_height,channels)\n",
    "    # Define model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv3D(filtersize[0], \n",
    "                 kernel_size=(2,2,2), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "    model.add(Conv3D(filtersize[1], \n",
    "                 kernel_size=(2,2,2), \n",
    "                 padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "    model.add(Conv3D(filtersize[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "\n",
    "    #Flatten Layers\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(dense_neurons[0], activation='relu'))\n",
    "    \n",
    "    \n",
    "    model.add(Dense(dense_neurons[1], activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #softmax layer\n",
    "    model.add(Dense(dense_neurons[2], activation='softmax'))\n",
    "\n",
    "    optimiser = 'adam' #write your optimizer\n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3d1_model0=define_model()\n",
    "conv_3d1_model0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 15\n",
    "\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, augument_false=True)\n",
    "val_generator = generator(val_path, val_doc, batch_size, augument_false=True)\n",
    "\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"Total Params:\", base_model.count_params())\n",
    "history_model3 =conv_3d1_model0.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "- Reducing kernel size from (3,3,3) to (2,2,2) increase the depth of the network a bit and thus improve the performance a bit.\n",
    "- Let tune the model by updating the model by adding more layers, dropout, reducing parameters and tuning hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. CNN CONV3D\n",
    "\n",
    "Let tune the model by updating the model by adding more layers, dropout, reducing parameters and tuning hyperparameters. Batch Size = 10, and No. of Epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    filtersize = [8,16,32,64]\n",
    "    dense_neurons = [256, 128, 5]\n",
    "    \n",
    "    # Input\n",
    "    input_shape=(total_frames,image_width,image_height,channels)\n",
    "    # Define model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv3D(filtersize[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "    model.add(Conv3D(filtersize[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "    model.add(Conv3D(filtersize[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "    model.add(Conv3D(filtersize[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "    #Flatten Layers\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(dense_neurons[0], activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(dense_neurons[1], activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #softmax layer\n",
    "    model.add(Dense(dense_neurons[2], activation='softmax'))\n",
    "\n",
    "    optimiser = 'adam' #write your optimizer\n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3d1_model=define_model()\n",
    "conv_3d1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 40\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, augument_false=True)\n",
    "val_generator = generator(val_path, val_doc, batch_size, augument_false=True)\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "history_model4 =conv_3d1_model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_model4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "From the accuracy score, loss value and the plot, we can say this model is doing decent.\n",
    "* Training Accuracy : 80.10 %\n",
    "* Validation Accuracy : 80.00 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. CONV2D & LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(lstm_cells=128,dense_neurons=128,dropout=0.5):\n",
    "      \n",
    "        inputshape=(total_frames,image_width,image_height,channels)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),\n",
    "                                  input_shape=inputshape))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(256, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        \n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(LSTM(lstm_cells))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "        optimiser = keras.optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN CNN MODEL SUMMARY\n",
    "rnn_cnn1_model=define_model()\n",
    "rnn_cnn1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 30\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, augument_false=True)\n",
    "val_generator = generator(val_path, val_doc, batch_size, augument_false=True)\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"Total Params:\", rnn_cnn1_model.count_params())\n",
    "history_model5=rnn_cnn1_model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_model5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "Similar outcome as previous model, no significant improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. CONV2D with GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(lstm_cells,dense_neurons,dropout):\n",
    "        \n",
    "        inputshape=(total_frames,image_width,image_height,channels)\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),\n",
    "                                  input_shape=inputshape))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "    \n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(GRU(lstm_cells))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "        \n",
    "        optimiser = keras.optimizers.Adam(lr=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cnn2_model=define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
    "rnn_cnn2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 25\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, augument_false=True)\n",
    "val_generator = generator(val_path, val_doc, batch_size, augument_false=True)\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"Total Params:\", rnn_cnn2_model.count_params())\n",
    "history_model6=rnn_cnn2_model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_model6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis<br>\n",
    "The training accuracy is 91.5 %, whereas the validation accuracy is 79%, the score is very good, but there is a difference of around 13%. Hence it might be a reason of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Transfer Learning with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the MobileNet model due to it's lightweight architecture and high speed performance as compared \n",
    "# to other heavy-duty models like VGG16, Alexnet, InceptionV3 etc. Also, we are now also running on low disk space \n",
    "from keras.applications import mobilenet\n",
    "mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
    "\n",
    "def define_model(lstm_cells=64,dense_neurons=64,dropout=0.25):\n",
    "        #inputshape=(len(img_arr[0]), img_arr[1], img_arr[2], img_arr[3])\n",
    "        inputshape=(total_frames,image_width,image_height,channels)\n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(mobilenet_transfer,input_shape=inputshape))\n",
    "        \n",
    "        \n",
    "        for layer in model.layers:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        \n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "        model.add(LSTM(lstm_cells))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "        \n",
    "        \n",
    "        optimiser = keras.optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cnn_tl_model=define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
    "rnn_cnn_tl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 25\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, augument_false=True)\n",
    "val_generator = generator(val_path, val_doc, batch_size, augument_false=True)\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"Total Params:\", rnn_cnn_tl_model.count_params())\n",
    "history_model7=rnn_cnn_tl_model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_model7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis<br>\n",
    "After transfer learning, we can see that the train accuracy has come up by 3 %, where as the validation accuracy increased by 5 %. There is a little improvement from the last CNN + RRN GRU model score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Transfer Learning Mobilenet with GRU and training all weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import mobilenet\n",
    "\n",
    "mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
    "\n",
    "    \n",
    "def define_model(gru_cells=64,dense_neurons=64,dropout=0.25):\n",
    "        inputshape=(total_frames,image_width,image_height,channels)\n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(mobilenet_transfer,input_shape=(inputshape)))\n",
    " \n",
    "        \n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "        model.add(GRU(gru_cells))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "        optimiser = keras.optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cnn_tl2_model=define_model(gru_cells=128,dense_neurons=128,dropout=0.25)\n",
    "rnn_cnn_tl2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 25\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, augument_false=True)\n",
    "val_generator = generator(val_path, val_doc, batch_size, augument_false=True)\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "\n",
    "print(\"Total Params:\", rnn_cnn_tl2_model.count_params())\n",
    "history_model8=rnn_cnn_tl2_model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_model8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis<br>\n",
    "Excellent score! 99.0% Training accuracy and 97% validation accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After above experimentation, I finalized  Model 4 - CNN-CONV3D which performed well.\n",
    "#### Reason:\n",
    "* <b>Training Accuracy : 80.10%, Validation Accuracy : 80.00%<b>\n",
    "* Number of Parameters(864,101) which is far less than other models in the experiment.\n",
    "* The best weights of CNN-CONV3D: <b>model-00040-0.47452-0.80100-0.62756-0.80000<b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
